{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a40aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b12ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99cbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine Quality Red dataset\n",
    "dataset =  pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3287c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80879013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a22429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.4    0.7    0.    ...  3.51   0.56   9.4  ]\n",
      " [ 7.8    0.88   0.    ...  3.2    0.68   9.8  ]\n",
      " [ 7.8    0.76   0.04  ...  3.26   0.65   9.8  ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  3.42   0.75  11.   ]\n",
      " [ 5.9    0.645  0.12  ...  3.57   0.71  10.2  ]\n",
      " [ 6.     0.31   0.47  ...  3.39   0.66  11.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008307fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 5 ... 6 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad998f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into an 80-20 training-test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585a10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the StandardScaler class\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6453f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the StandardScaler on the features from the training set and transform it\n",
    "X_train[:,:] = sc.fit_transform(X_train[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3302de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transform to the test set\n",
    "X_test[:,:] = sc.transform(X_test[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f81ba8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21833164  0.88971201  0.19209222 ...  1.09349989  0.45822284\n",
      "   1.12317723]\n",
      " [-1.29016623 -1.78878251  0.65275338 ... -0.40043872 -0.40119696\n",
      "   1.40827174]\n",
      " [ 1.49475291 -0.78434707  1.01104539 ... -0.07566946  0.51551749\n",
      "  -0.58738978]\n",
      " ...\n",
      " [-0.65195559  0.49909822 -1.08752211 ...  1.28836145 -0.68767023\n",
      "  -0.87248428]\n",
      " [-0.24582155 -1.84458448  0.39683051 ...  0.05423824  0.80199076\n",
      "   1.40827174]\n",
      " [-1.46422367 -1.34236676 -0.06383064 ...  0.50891521 -0.68767023\n",
      "   2.92877575]]\n"
     ]
    }
   ],
   "source": [
    "# Print the scaled training and test datasets\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4375138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.61859850e-01  1.64286407e-01 -9.85152962e-01 ... -4.65392578e-01\n",
      "  -1.34389336e-04 -7.77452782e-01]\n",
      " [-3.03840702e-01 -1.70525408e-01 -5.24491803e-01 ...  5.08915214e-01\n",
      "  -1.03143815e+00 -8.72484283e-01]\n",
      " [ 1.37871461e+00  7.78108067e-01 -2.68568937e-01 ... -2.05577167e-01\n",
      "   1.83329452e+00 -4.92358280e-01]\n",
      " ...\n",
      " [-1.37449586e-02  3.87494284e-01 -1.15015218e-01 ... -1.04997725e+00\n",
      "  -7.44964886e-01 -5.87389780e-01]\n",
      " [ 2.76350785e-01 -1.45397070e+00  6.01568807e-01 ... -1.04997725e+00\n",
      "   1.71749571e-01  7.43051230e-01]\n",
      " [ 4.50408230e-01  1.30822677e+00 -1.18989125e+00 ... -1.40623314e-01\n",
      "  -6.87670232e-01 -6.82421281e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc07a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a93f3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "linearClassifier = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5dd1a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ad783d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.34666441, 5.05631345, 5.66446972, 5.46451484, 5.72518476,\n",
       "       5.27928659, 5.03421667, 5.12623347, 5.74534288, 5.68665032,\n",
       "       6.13959677, 5.23386892, 5.54991474, 5.25825299, 5.44810502,\n",
       "       6.46828999, 5.15018088, 5.59105157, 6.5560658 , 5.32255751,\n",
       "       5.3918385 , 5.19610791, 5.94475739, 6.36197631, 5.35484893,\n",
       "       5.41907575, 6.36483321, 5.35121573, 5.172392  , 6.16987311,\n",
       "       5.25263058, 5.50657406, 5.75422105, 5.39101712, 5.45331031,\n",
       "       5.02757499, 6.16173243, 5.68661555, 5.6486077 , 6.165471  ,\n",
       "       5.52872593, 5.24414488, 6.17724727, 5.16500868, 5.87598332,\n",
       "       5.81317121, 6.41982782, 5.6059474 , 5.15232137, 5.55634632,\n",
       "       5.16044852, 5.10449459, 5.58371721, 6.33425313, 4.95134985,\n",
       "       4.98364804, 6.01041999, 5.40809804, 5.83802638, 5.2486897 ,\n",
       "       5.60717482, 5.96630957, 5.27619063, 5.30380113, 6.4949309 ,\n",
       "       5.42033967, 6.34273471, 5.24618531, 6.41317317, 5.31237924,\n",
       "       6.41746963, 4.74315748, 5.79362039, 5.8283184 , 6.17598768,\n",
       "       5.29723707, 6.76198733, 5.89745261, 6.07833712, 6.43522754,\n",
       "       5.29499011, 6.4546625 , 5.45007864, 5.69644693, 5.72368681,\n",
       "       6.41233601, 5.31025119, 5.84548953, 6.31433877, 5.20585049,\n",
       "       6.10141578, 5.70349712, 5.78679322, 5.93173502, 5.1852885 ,\n",
       "       5.74819506, 5.17351769, 5.69336056, 4.99158806, 5.52004223,\n",
       "       5.06867029, 5.13831807, 5.84991801, 5.72612872, 5.47766711,\n",
       "       6.12476389, 5.73551897, 5.44180611, 6.08785125, 5.24667513,\n",
       "       6.68434941, 5.26499691, 6.15359147, 4.74493131, 5.82508834,\n",
       "       5.9872331 , 6.17033538, 5.50859099, 5.02156367, 5.83326942,\n",
       "       6.21086737, 5.26363047, 5.75354145, 5.38942262, 5.39641713,\n",
       "       5.25966957, 6.21024761, 5.69536196, 5.58586923, 5.82155344,\n",
       "       5.79362039, 5.14962195, 5.01142496, 6.34824026, 5.55634632,\n",
       "       5.08213438, 5.05668453, 5.3517036 , 5.11920475, 5.66948552,\n",
       "       6.01614582, 6.03912287, 6.2439487 , 5.48155178, 5.86335248,\n",
       "       5.26302973, 6.06162683, 5.4041289 , 5.99869245, 5.06897434,\n",
       "       5.70161041, 6.14167652, 5.11821365, 5.67658854, 5.79362039,\n",
       "       6.0891404 , 5.22103588, 5.90134727, 5.48941228, 5.93412645,\n",
       "       6.3118134 , 5.71785286, 6.13152024, 4.9898825 , 5.39143155,\n",
       "       5.63146602, 4.70626967, 5.232132  , 5.04110749, 4.99137335,\n",
       "       5.20669998, 5.11005631, 6.29652093, 5.48263655, 5.73380671,\n",
       "       5.86096397, 6.11131909, 5.38204246, 5.39418516, 5.11161705,\n",
       "       4.74487438, 6.34043215, 5.57642863, 6.52465957, 5.18100269,\n",
       "       6.37846442, 5.39147732, 5.7435927 , 6.71436012, 5.48263655,\n",
       "       5.42573746, 6.08035849, 5.6017508 , 6.52660959, 5.79174569,\n",
       "       5.32807323, 4.92850887, 5.40669848, 5.49983794, 6.12476389,\n",
       "       5.36974106, 5.78401123, 5.48534309, 5.02135392, 6.65592712,\n",
       "       5.62370825, 4.83368748, 5.73347951, 5.68074781, 6.09738854,\n",
       "       5.99258428, 5.16969289, 5.7770828 , 6.59697123, 6.37009025,\n",
       "       5.77981876, 5.46465189, 5.19009343, 5.80517998, 5.30830978,\n",
       "       5.09158113, 6.24863165, 6.33674607, 5.99341483, 5.16829696,\n",
       "       4.81289689, 5.22265229, 6.44901207, 5.48931502, 5.31886287,\n",
       "       5.5589884 , 5.04938167, 6.32905554, 5.98208683, 6.04415923,\n",
       "       6.12476389, 5.37906696, 5.72368681, 4.795237  , 5.03676054,\n",
       "       5.68938109, 5.01079638, 5.83995808, 6.13732216, 5.24782156,\n",
       "       5.56627333, 6.00210169, 5.3626292 , 6.68219105, 5.11532126,\n",
       "       5.78120835, 5.62454656, 5.31952796, 5.51514228, 5.20719665,\n",
       "       5.13154551, 5.48620652, 5.85075029, 5.71919777, 6.80397753,\n",
       "       6.20404528, 6.04410296, 5.38204246, 6.50598024, 5.85449947,\n",
       "       6.30306847, 5.05268393, 4.92613186, 5.94872379, 6.32176541,\n",
       "       5.18546252, 5.8361393 , 5.40120414, 5.17199122, 5.3095161 ,\n",
       "       5.49911144, 5.66556707, 6.21315993, 6.22227229, 5.26433184,\n",
       "       6.48967503, 4.95165562, 5.37197617, 5.49931461, 5.3577211 ,\n",
       "       5.82641444, 4.97385804, 6.03912287, 5.03990278, 5.76144224,\n",
       "       5.67870975, 6.57726748, 5.67261468, 5.5851728 , 4.92156862,\n",
       "       6.38162382, 5.10784567, 6.30108784, 6.21224582, 6.50221084,\n",
       "       5.51985221, 5.16412612, 6.23283235, 5.32903476, 5.25839032,\n",
       "       5.32882382, 5.89753508, 5.92128255, 6.26545355, 6.57918909,\n",
       "       5.55219907, 5.56483453, 5.51937934, 5.61558301, 5.39101712,\n",
       "       5.68815279, 5.23225544, 5.2805354 , 6.2724663 , 5.19707213])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f20d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save involved models\n",
    "import pickle\n",
    "pickle.dump(sc, open('models/StandardScaler.pkl', 'wb'))\n",
    "pickle.dump(linearClassifier, open('models/LinearRegressor.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
